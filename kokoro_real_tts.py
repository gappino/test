#!/usr/bin/env python3
"""
Real Kokoro TTS Script - Using actual Kokoro synthesis
"""

import sys
import os
import json
import tempfile
from pathlib import Path

# Redirect warnings to stderr
import warnings
warnings.filterwarnings("ignore")

def main():
    try:
        # Get input from command line arguments
        if len(sys.argv) < 2:
            print(json.dumps({"error": "No text provided"}))
            sys.exit(1)
        
        text = sys.argv[1]
        voice = sys.argv[2] if len(sys.argv) > 2 else 'af_heart'
        output_dir = sys.argv[3] if len(sys.argv) > 3 else './uploads/audio'
        
        # Ensure voice is a valid Kokoro voice
        if not voice.startswith(('af_', 'am_', 'bf_', 'bm_')):
            voice = 'af_heart'  # Default to a valid voice
        
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)
        
        # Import Kokoro
        try:
            from kokoro import KPipeline
            import soundfile as sf
            import torch
            import numpy as np
        except ImportError as e:
            print(json.dumps({"error": f"Kokoro not available: {e}"}))
            sys.exit(1)
        
        # Initialize Kokoro TTS Pipeline with model
        try:
            # Create pipeline for English (American) with model
            pipeline = KPipeline(lang_code='a', model=True, device='cpu')
            print("Pipeline with model created successfully", file=sys.stderr)
        except Exception as e:
            print(f"Failed to initialize pipeline with model: {e}", file=sys.stderr)
            try:
                # Fallback: try without model
                pipeline = KPipeline(lang_code='a', model=False, device='cpu')
                print("Pipeline without model created successfully", file=sys.stderr)
            except Exception as e2:
                print(json.dumps({"error": f"Failed to initialize pipeline (with and without model): {e2}"}))
                sys.exit(1)
        
        # Calculate duration
        words = len(text.split())
        duration = max(2.0, words * 0.5)
        
        # Generate output filename
        output_file = os.path.join(output_dir, f'kokoro_real_{int(os.urandom(4).hex(), 16)}.wav')
        
        # Generate speech using Kokoro
        try:
            audio_chunks = []
            
            # Split long text into sentences for better processing
            sentences = text.split('. ')
            if len(sentences) > 1:
                print(f"Processing {len(sentences)} sentences separately", file=sys.stderr)
                for sentence in sentences:
                    if sentence.strip():
                        # Add period back if it was removed by split
                        if not sentence.endswith('.') and not sentence.endswith('!') and not sentence.endswith('?'):
                            sentence += '.'
                        
                        print(f"Processing sentence: {sentence[:50]}...", file=sys.stderr)
                        for result in pipeline(sentence, voice=voice):
                            if result.audio is not None:
                                audio_data = result.audio.cpu().numpy()
                                audio_chunks.append(audio_data)
                                print(f"Generated audio chunk: {len(audio_data)} samples", file=sys.stderr)
            else:
                # Process single sentence
                for result in pipeline(text, voice=voice):
                    if result.audio is not None:
                        audio_data = result.audio.cpu().numpy()
                        audio_chunks.append(audio_data)
                        print(f"Generated audio chunk: {len(audio_data)} samples", file=sys.stderr)
            
            if not audio_chunks:
                print(json.dumps({"error": "No audio generated by Kokoro"}))
                sys.exit(1)
            
            # Concatenate audio chunks
            full_audio = np.concatenate(audio_chunks)
            
            # Ensure audio is in the right format
            if full_audio.ndim > 1:
                full_audio = full_audio.flatten()
            
            # Normalize audio
            if np.max(np.abs(full_audio)) > 0:
                full_audio = full_audio / np.max(np.abs(full_audio)) * 0.8
            
            # Save audio
            sf.write(output_file, full_audio, 24000)
            
            # Calculate actual duration
            actual_duration = len(full_audio) / 24000
            
        except Exception as e:
            print(json.dumps({"error": f"Kokoro synthesis failed: {e}"}))
            sys.exit(1)
        
        # Check if file was created
        if not os.path.exists(output_file):
            print(json.dumps({"error": "Audio file was not created"}))
            sys.exit(1)
        
        # Get file size
        file_size = os.path.getsize(output_file)
        
        # Return result
        result = {
            "success": True,
            "audio_url": output_file,
            "audio_file": output_file,  # Keep both for compatibility
            "duration": actual_duration,
            "text": text,
            "voice": voice,
            "sample_rate": 24000,
            "words": words,
            "file_size": file_size,
            "engine": "Real Kokoro TTS",
            "note": "Generated using actual Kokoro TTS synthesis"
        }
        
        print(json.dumps(result))
        
    except Exception as e:
        print(json.dumps({"error": str(e)}))
        sys.exit(1)

if __name__ == "__main__":
    main()
